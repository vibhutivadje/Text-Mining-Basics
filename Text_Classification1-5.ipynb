{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Zara\n",
      "Age\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#dict are very often used for text classification\n",
    "dict = {'Name': 'Zara', 'Age': 7}\n",
    "for x in dict:\n",
    "    print(x)\n",
    "    print(dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1st entry': 34, '2nd entry': True, '3rd entry': 'text'}\n"
     ]
    }
   ],
   "source": [
    "emptydict={}\n",
    "emptydict['1st entry']=34\n",
    "emptydict['2nd entry']=True\n",
    "emptydict['3rd entry']='text'\n",
    "print(emptydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# assign values using for\n",
    "f=[x for x in range(1,10)]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5), (1, 6), (2, 5), (2, 6), (3, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "g=[(x,y) for x in range(1,4) for y in range(5,7)]\n",
    "print(g) # for each x, populate all possible y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5), (2, 5), (3, 5), (1, 6), (2, 6), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "h=[(x,y) for y in range(5,7) for x in range(1,4)]\n",
    "print(h) # for each y, populates all possible x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (3, 5)]\n"
     ]
    }
   ],
   "source": [
    "r=[(x,y) for x in range(1,4) for y in range(x+1,x+3)]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key1': 1, 'key2': 2, 'key3': 3, 'key4': 4}\n"
     ]
    }
   ],
   "source": [
    "values=[1,2,3,4]\n",
    "keys=['key1','key2','key3','key4']\n",
    "dict1={'{}'.format(x):y for x,y in zip(keys, values)}\n",
    "print(dict1)\n",
    "# for x,y in zip(keys,values):\n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 2), (10, 4), (26, 6)]\n"
     ]
    }
   ],
   "source": [
    "tuple_list=[(1,2),(3,4),(5,6)]\n",
    "j=[(x**2+1,y) for (x,y) in tuple_list]\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to just find the keys, we can either convert the dictionary to a list or use the dictionary in a context where a list is expected, as the parameter of sorted()\n",
    "or in a for loop ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st entry', '2nd entry', '3rd entry']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = list(emptydict)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd entry', '3rd entry']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st entry', '2nd entry', '3rd entry']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(emptydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('1st entry', 34), ('2nd entry', True), ('3rd entry', 'text')])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emptydict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example\n",
    "d = {}\n",
    "d[key] = value\n",
    "d.keys()\n",
    "list(d)\n",
    "sorted(d)\n",
    "key in d\n",
    "for key in d\n",
    "d.values()\n",
    "dict([(k1,v1), (k2,v2), ...]) d1.update(d2) defaultdict(int)\n",
    "\n",
    "Description\n",
    "Create an empty dictionary and assign it to d Assign a value to a given dictionary key\n",
    "The list of keys of the dictionary\n",
    "The list of keys of the dictionary\n",
    "The keys of the dictionary, sorted\n",
    "Test whether a particular key is in the dictionary Iterate over the keys of the dictionary\n",
    "The list of values in the dictionary\n",
    "Create a dictionary from a list of key-value pairs Add all items from d2 to d1\n",
    "A dictionary whose default value is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1,come up the object set\n",
    "#object set is list of tuples. Each tuple is an object.\n",
    "#objectset=[(text,class),(text,class).......(text,class)]\n",
    "\n",
    "\n",
    "#step 2, come up with feature function. we cannot make prediction based on pure text. \n",
    "# define a feature function\n",
    "# def feature(text) -> features as dictionary\n",
    "\n",
    "#'times' -> {'first_letter':'t','last_letter':'s'}\n",
    "\n",
    "# first_letter:feature1\n",
    "# last_letter:feature2\n",
    "\n",
    "#step 3, convert the object set to feature set using feature function\n",
    "#feature set=[({dict1},class),({dict2},class).......({dict3},class)]\n",
    "\n",
    "#step 4, randomly generate training and testing set 80/20,90/10\n",
    "\n",
    "#step 5, train the model and testing the accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    }
   ],
   "source": [
    "#Predict gender identification from name\n",
    "#check out some names in the nltk corpus package\n",
    "from nltk.corpus import names \n",
    "import random\n",
    "print(names.words('male.txt')[:10])#datastrucutre is list\n",
    "print(names.words('female.txt')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Arlena', 'female'), ('Rachelle', 'female'), ('Hadria', 'female'), ('Jacintha', 'female'), ('Lemuel', 'male'), ('Arline', 'female'), ('Gilli', 'female'), ('Darby', 'male'), ('Bonnee', 'female'), ('Gere', 'male')]\n"
     ]
    }
   ],
   "source": [
    "#step1, generate the object set\n",
    "male=[(text,'male') for text in names.words('male.txt')]\n",
    "female=[(text,'female') for text in names.words('female.txt')]\n",
    "allnames = male + female\n",
    "random.shuffle(allnames)\n",
    "print(allnames[:10]) # as all are male names we need to do a random shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter': 'k'}\n"
     ]
    }
   ],
   "source": [
    "#step 2, come up with feature function. we cannot make prediction based on pure text. \n",
    "\n",
    "#we are going to use the the last letter as the feature to classify\n",
    "#program the feature extractor\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]} #always returns dict\n",
    "print(gender_features('Shrek'))\n",
    "#the out put is {'last_letter': 'k'}, which is a list of features\n",
    "#you have to follow this format in creating features out of texts\n",
    "#this format is called dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_letter': 'h'}, 'male'), ({'last_letter': 'y'}, 'female'), ({'last_letter': 'g'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'c'}, 'male'), ({'last_letter': 'n'}, 'female'), ({'last_letter': 'n'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'n'}, 'male')]\n"
     ]
    }
   ],
   "source": [
    "#step 3, convert the object set to feature set using feature function\n",
    "\n",
    "# define the featureset and corresponding class\n",
    "# the feature set is is a list of tuples\n",
    "# male_name=[(name, 'male') for name in names.words('male.txt')] # build the training/testing set in a format (input, class)\n",
    "# female_name=[(name, 'female') for name in names.words('female.txt')]\n",
    "# all_names=male_name+female_name\n",
    "# import random\n",
    "random.shuffle(allnames)\n",
    "featuresets=[(gender_features(n),g) for (n,g) in allnames[:1000]] # convert the training/testing set in a format ({the feature dictionary},class)\n",
    "print(featuresets[:10])#list of tuple. first element fo tuple is dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_letter': 'e'}, 'female'), ({'last_letter': 't'}, 'male'), ({'last_letter': 'k'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'l'}, 'male'), ({'last_letter': 'y'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'a'}, 'female')]\n"
     ]
    }
   ],
   "source": [
    "#step 4, randomly generate training and testing set 80/20,90/10\n",
    "# define the training set and testing set size\n",
    "train_set=featuresets[:800]\n",
    "test_set=featuresets[800:]\n",
    "print(test_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5, train the model and testing the accuracy\n",
    "import nltk\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "# classify some names # the classify function takes features as argument\n",
    "print(classifier.classify({'last_letter':'y'}))#input to the model used be featureset i.e dict\n",
    "print(classifier.classify(gender_features('peng')))#return the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy\n",
    "correct_prediction=0 # reset values records correct pred\n",
    "total_prediction=0 # reset values total number of pred\n",
    "for i in test_set:\n",
    "    total_prediction+=1\n",
    "#     print(i[1])\n",
    "    feature=i[0] #eg:{'last_letter': 'k'} for each tuple ({the feature dictionary},class) in the feature set, [0] is the feature, [1] is the class\n",
    "    g=i[1] #class\n",
    "    if classifier.classify(feature)==g:\n",
    "        correct_prediction+=1\n",
    "print(correct_prediction/total_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the confusion table\n",
    "actual=[]\n",
    "predicted=[]\n",
    "for i in test_set:\n",
    "    actual.append(i[1])#[i] is the class\n",
    "    predicted.append(classifier.classify(i[0]))# predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  23]\n",
      " [ 23  50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(actual, predicted))\n",
    "#104 - tp: truely classified actual is female, predicted as female\n",
    "#23 - fp: actual is female, predicted as male\n",
    "#23 - fn: actual is male, predicted as female\n",
    "#50 - tn: truely classified actual is male, predicted as male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted  female  male\n",
      "Actual                 \n",
      "female        104    23\n",
      "male           23    50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_actu = pd.Series(actual, name='Actual')\n",
    "y_pred = pd.Series(predicted, name='predicted')\n",
    "print(pd.crosstab(y_actu, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task: predict if a name is female name\n",
    "#precision, recall and f1_score\n",
    "\n",
    "#tp: actual is female, predicted as female\n",
    "#fp: actual is male, predicted as female\n",
    "#fn: actual is female and predicted as male\n",
    "\n",
    "#precision is tp/(tp+fp) -> among all predicted positives, how many are correct?\n",
    "#recall is tp/(tp+fn) -> among all actual positives, how many are identified correctly?\n",
    "#f1_score is the average of precision and recall. f1=1/precision+1/recall\n",
    "\n",
    "#accuracy -> TP+TN/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate the precision, recall, f1_score when predicting if a name is a female name.\n",
    "# all three measures can only be calculated with 0 and 1 labels.\n",
    "y_true=[1 if x==\"female\" else 0 for x in actual]\n",
    "y_predicted=[1 if x==\"female\" else 0 for x in predicted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188976377952756\n"
     ]
    }
   ],
   "source": [
    "# The precision is the ratio tp / (tp + fp)\n",
    "import sklearn\n",
    "print(sklearn.metrics.precision_score(y_true, y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188976377952756\n"
     ]
    }
   ],
   "source": [
    "# The recall is tp / (tp + fn)\n",
    "print(sklearn.metrics.recall_score(y_true, y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188976377952756\n"
     ]
    }
   ],
   "source": [
    "# f1_score is the geometric average of precision and recall, a general measure of prediction power.\n",
    "print(sklearn.metrics.f1_score(y_true, y_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. gender identification with more features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we believe that the consecutive letters are important features, \n",
    "# for the name james, the list of consecutive letters are ['ja','am','me','es'].\n",
    "# in this example, we will find the 100 most common two-consecutive letters, and use them as the feature as well.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import names \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'ar', 'el', 'ri', 'in', 'er', 'ne', 'ie', 'le', 'li', 'na', 'en', 'll', 'or', 'ma', 'al', 'la', 're', 'ra', 'nn', 'on', 'ia', 'ha', 'il', 'ta', 'is', 'he', 'ni', 'et', 'da', 'te', 'de', 'ro', 'st', 'be', 'nd', 'th', 'tt', 'sa', 'ch', 'ca', 'ol', 'ti', 'ly', 'di', 'me', 'lo', 'mi', 'ic', 'at', 'sh', 'ee', 'yn', 'ka', 'es', 'ey', 'am', 'it', 'do', 'se', 'rr', 'ce', 'rt', 'to', 'ad', 'ry', 'si', 'ge', 'rl', 'vi', 'ea', 'ss', 'co', 'as', 'ai', 'au', 'ed', 'rd', 'jo', 'br', 'ab', 'nt', 'mo', 'us', 'hi', 'ke', 'ga', 'ba', 'ur', 'os', 'je', 'em', 'no', 'ay', 'ja', 'ci', 'gi', 'ac', 'dr', 'rn']\n"
     ]
    }
   ],
   "source": [
    "namelist=names.words('male.txt')+names.words('female.txt') #combine two list \n",
    "#lily -> lily[:-1] = lil\n",
    "#lily -> lily[1:] = ily\n",
    "# print([(x,y) for x,y in zip('lily'[:-1],'lily'[1:])])\n",
    "consequtive=['{}{}'.format(i,j).lower() for k in namelist for i,j in zip(k[:-1],k[1:])] #extract \n",
    "# print(consequtive[:100])\n",
    "freq=nltk.FreqDist(consequtive) #find the most common letter\n",
    "# print(freq.most_common(100)) #returns tuple\n",
    "most_common=[i for i,j in freq.most_common(100)]\n",
    "print(most_common)\n",
    "#feature set look like\n",
    "#eg:'anna' ->{'an':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1 : object set\n",
    "# define the feature set\n",
    "male_name=[(name, 'male') for name in names.words('male.txt')]\n",
    "female_name=[(name, 'female') for name in names.words('female.txt')]\n",
    "all_names=male_name+female_name\n",
    "random.shuffle(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an': True, 'ar': False, 'el': False, 'ri': False, 'in': False, 'er': False, 'ne': False, 'ie': False, 'le': False, 'li': False, 'na': True, 'en': False, 'll': False, 'or': False, 'ma': False, 'al': False, 'la': False, 're': False, 'ra': False, 'nn': True, 'on': False, 'ia': False, 'ha': False, 'il': False, 'ta': False, 'is': False, 'he': False, 'ni': False, 'et': False, 'da': False, 'te': False, 'de': False, 'ro': False, 'st': False, 'be': False, 'nd': False, 'th': False, 'tt': False, 'sa': False, 'ch': False, 'ca': False, 'ol': False, 'ti': False, 'ly': False, 'di': False, 'me': False, 'lo': False, 'mi': False, 'ic': False, 'at': False, 'sh': False, 'ee': False, 'yn': False, 'ka': False, 'es': False, 'ey': False, 'am': False, 'it': False, 'do': False, 'se': False, 'rr': False, 'ce': False, 'rt': False, 'to': False, 'ad': False, 'ry': False, 'si': False, 'ge': False, 'rl': False, 'vi': False, 'ea': False, 'ss': False, 'co': False, 'as': False, 'ai': False, 'au': False, 'ed': False, 'rd': False, 'jo': False, 'br': False, 'ab': False, 'nt': False, 'mo': False, 'us': False, 'hi': False, 'ke': False, 'ga': False, 'ba': False, 'ur': False, 'os': False, 'je': False, 'em': False, 'no': False, 'ay': False, 'ja': False, 'ci': False, 'gi': False, 'ac': False, 'dr': False, 'rn': False, 'last_letter': 'a'}\n"
     ]
    }
   ],
   "source": [
    "#feature set look like\n",
    "#eg:'anna' ->{'an':True}\n",
    "\n",
    "#step:2 \n",
    "# define the feature function\n",
    "def gender_features(word):\n",
    "    word=word.lower()\n",
    "    feature={}\n",
    "    for i in most_common:\n",
    "        feature[i]=i in word\n",
    "    feature['last_letter']=word[-1]\n",
    "    return feature\n",
    "print(gender_features('anna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step:3\n",
    "#define the featureset\n",
    "featuresets=[(gender_features(n),g) for (n,g) in all_names] #list of tuple. 2 tuples.\n",
    "\n",
    "#step 4\n",
    "train_set=featuresets[:]\n",
    "test_set=featuresets[:] # use full sample to increase the stablility of the accracy\n",
    "#\n",
    "#step 5: Train and evalute\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7899043303121853\n"
     ]
    }
   ],
   "source": [
    "# calculate the prediction accuracy\n",
    "correct_prediction=0 # reset values\n",
    "total_prediction=0 # reset values\n",
    "for i in test_set:\n",
    "    total_prediction+=1\n",
    "    feature=i[0] # for each tuple ({the feature dictionary},class) in the feature set, [0] is the feature, [1] is the class\n",
    "    g=i[1]\n",
    "    if classifier.classify(feature)==g: #if the predicted class is equal to true class add 1\n",
    "        correct_prediction+=1\n",
    "print(correct_prediction/total_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie review Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the occurrence of the most popular words in a movie review, we classify the review category (positive or negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "#check things in the movie_reviews package\n",
    "print(movie_reviews.categories()) #there are only two categories ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(movie_reviews.fileids('pos')) #list all reviews with positive category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(movie_reviews.fileids('neg')) #list all reviews with positive category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'party', 'guys', 'bob', 'their', 'heads', 'to', ...]\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.words('neg/cv999_14636.txt')) #check the words in one review file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...], 'neg')\n"
     ]
    }
   ],
   "source": [
    "#step1, object set - list of tuple\n",
    "#pbjectset = [(review_text,category)]\n",
    "#create a tuple with a bag of words in the review and the review category\n",
    "documents=[(movie_reviews.words(fileid),category)\n",
    "           for category in movie_reviews.categories()#either pos or neg\n",
    "           for fileid in movie_reviews.fileids(category)]\n",
    "print(documents[1]) #check it out\n",
    "# random.shuffle(documents) #randomize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all word in the reviews\n",
    "all_words=[x.lower() for x in movie_reviews.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "#check the most frequent words in all movie reviews\n",
    "all_words_freq=nltk.FreqDist(all_words)\n",
    "print(all_words_freq.most_common(15))\n",
    "print(all_words_freq['stupid'])#the frequency of 'stupid in all reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_words=[i[0] for i in all_words_freq.most_common(3000)] # get the most frequent word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define the feature extractor\n",
    "def document_features(doc):\n",
    "    words=set(doc) # get a unique list of all words\n",
    "    features={} # start contructing the feature set\n",
    "    for w in most_freq_words:\n",
    "        features[w] = (w in words) # check if the 3000 most frequent words are in the review\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(document_features(movie_reviews.words('neg/cv999_14636.txt'))) # try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the feature set\n",
    "featureset=[(document_features(d),c) for (d,c) in documents]\n",
    "print(featureset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and accuracy calculation\n",
    "training_set=featureset[:1900] # there are only 2000 movie reviews\n",
    "testing_set=featureset[1900:]\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(nltk.classify.accuracy(classifier,testing_set)) # turns out the accuracy is 77%\n",
    "classifier.show_most_informative_features(15) # show the most informative 15 features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "these are the most informative features \n",
    "in reviews with \"idiotic\", on average there are 12.1 negative review and 1 postive review\n",
    "\n",
    "                 idiotic = True              neg : pos    =     12.1 : 1.0\n",
    "                  annual = True              pos : neg    =     10.7 : 1.0\n",
    "               atrocious = True              neg : pos    =     10.5 : 1.0\n",
    "                   sucks = True              neg : pos    =      9.5 : 1.0\n",
    "                 frances = True              pos : neg    =      9.3 : 1.0\n",
    "           unimaginative = True              neg : pos    =      7.5 : 1.0\n",
    "                 cunning = True              pos : neg    =      7.0 : 1.0\n",
    "             silverstone = True              neg : pos    =      6.9 : 1.0\n",
    "                  sexist = True              neg : pos    =      6.9 : 1.0\n",
    "                  regard = True              pos : neg    =      6.9 : 1.0\n",
    "              schumacher = True              neg : pos    =      6.7 : 1.0\n",
    "                    mena = True              neg : pos    =      6.3 : 1.0\n",
    "                  shoddy = True              neg : pos    =      6.3 : 1.0\n",
    "                  suvari = True              neg : pos    =      6.3 : 1.0\n",
    "                 singers = True              pos : neg    =      6.3 : 1.0\n",
    "These ratios are called \"likelihood ratio\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. what about using the existence of most common adjectives as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 object set\n",
    "documents=[(movie_reviews.words(fileid),category)\n",
    "           for category in movie_reviews.categories()\n",
    "           for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1.5  retrieve the most frequent jjs\n",
    "docsample=random.sample(documents,200) \n",
    "# because retrieving jjs for all 2000 reviews can take a long time, so for illustration, \n",
    "#we only take a random sample of 200 reviews to extract the adjectives\n",
    "pos=[nltk.pos_tag(x) for x,y in docsample] # a list of lists of tuples, \n",
    "#each list of tuple is the pos of the movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjlist=[]\n",
    "for i in pos:\n",
    "    jjs=[x[0].lower() for x in i if 'JJ' in x[1] and len(x[0])>=3 and x[0].isalpha()] # the extra condition is to make sure that the adjectives are legit adjectives\n",
    "    jjlist+=jjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjfrequency=nltk.FreqDist(jjlist)\n",
    "freqjj=[x for x,y in jjfrequency.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 define the feature function \n",
    "def feature(text): # the text here is a list of word for each review\n",
    "    res={}\n",
    "    for i in freqjj:\n",
    "        res[i]=i in set([x.lower() for x in text])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 feature set\n",
    "random.shuffle(documents)\n",
    "featureset=[(feature(text),clas) for text, clas in documents] # only limit to the first 100 reviews, otherwise it takes too long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 train test divide\n",
    "train=featureset[:90]\n",
    "test=featureset[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6094240837696335\n",
      "Most Informative Features\n",
      "                 certain = True              pos : neg    =      5.2 : 1.0\n",
      "               enjoyable = True              pos : neg    =      5.0 : 1.0\n",
      "                   usual = True              neg : pos    =      4.2 : 1.0\n",
      "                     red = True              neg : pos    =      3.7 : 1.0\n",
      "                 several = True              neg : pos    =      3.4 : 1.0\n",
      "                    easy = True              pos : neg    =      3.2 : 1.0\n",
      "               hilarious = True              pos : neg    =      3.2 : 1.0\n",
      "                 similar = True              pos : neg    =      2.6 : 1.0\n",
      "                   worst = True              neg : pos    =      2.5 : 1.0\n",
      "                    deep = True              pos : neg    =      2.4 : 1.0\n",
      "                american = True              pos : neg    =      2.3 : 1.0\n",
      "                   sweet = True              pos : neg    =      2.3 : 1.0\n",
      "                     low = True              neg : pos    =      2.2 : 1.0\n",
      "                  latest = True              neg : pos    =      2.2 : 1.0\n",
      "                original = True              pos : neg    =      2.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# step 5 train and evaluate\n",
    "model=nltk.NaiveBayesClassifier.train(train)\n",
    "print(nltk.classify.accuracy(model,test))   \n",
    "model.show_most_informative_features(15) # show the most informative 15 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
