{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: {sys.executable}: command not found\n",
      "/bin/sh: {sys.executable}: command not found\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install vaderSentiment\n",
    "!{sys.executable} -m pip install textblob*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2.9)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (0.14.1)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (4.44.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (7.1.1)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. sentiment analysis with blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), ('general-purpose', 'JJ'), ('programming', 'NN'), ('language', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# textblob is a package built on NLTK, it can also do most of the task\n",
    "# pos with textblob\n",
    "from textblob import TextBlob\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "# print(wiki)\n",
    "text=\"Python is a high-level, general-purpose programming language.\"\n",
    "print(wiki.tags) # same result as the pos_tag\n",
    "# print(text.tags) # error, str doesn't have tags method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-20556c5eee3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# error, str doesn't have tags method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tags'"
     ]
    }
   ],
   "source": [
    "print(text.tags) # error, str doesn't have tags method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'textblob.blob.TextBlob'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# check the type of a textblob\n",
    "from textblob import TextBlob #trained method to do sentiment analysis\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "text=\"Python is a high-level, general-purpose programming language.\"\n",
    "print(type(wiki))\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cmpkey', '_compare', '_create_sentence_objects', '_strkey', 'analyzer', 'classifier', 'classify', 'correct', 'detect_language', 'ends_with', 'endswith', 'find', 'format', 'index', 'join', 'json', 'lower', 'ngrams', 'noun_phrases', 'np_counts', 'np_extractor', 'parse', 'parser', 'polarity', 'pos_tagger', 'pos_tags', 'raw', 'raw_sentences', 'replace', 'rfind', 'rindex', 'sentences', 'sentiment', 'sentiment_assessments', 'serialized', 'split', 'starts_with', 'startswith', 'string', 'strip', 'stripped', 'subjectivity', 'tags', 'title', 'to_json', 'tokenize', 'tokenizer', 'tokens', 'translate', 'translator', 'upper', 'word_counts', 'words']\n"
     ]
    }
   ],
   "source": [
    "# we can do all sorts of things with a textblob object\n",
    "atextblob=TextBlob('Python is a high-level, general-purpose programming language.')\n",
    "print(dir(atextblob))\n",
    "# we can see we have a bunch of functions, but not as many as nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python是一种高级通用编程语言。\n",
      "Python es un lenguaje de programación de alto nivel y propósito general.\n"
     ]
    }
   ],
   "source": [
    "# we can do translation\n",
    "from textblob import TextBlob\n",
    "atextblob=TextBlob('Python is a high-level, general-purpose programming language.')\n",
    "print(atextblob.translate(to='zh-CN'))\n",
    "print(atextblob.translate(to='es'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    }
   ],
   "source": [
    "# detect language\n",
    "from textblob import TextBlob\n",
    "b = TextBlob(\"Python es un lenguaje de programación de alto nivel, de propósito general\")\n",
    "print(b.detect_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.4642857142857143, subjectivity=1.0)\n"
     ]
    }
   ],
   "source": [
    "# extracting the sentiment\n",
    "# textblob sentiment is a trained Naive Bayes model based on some preclassified corpus \n",
    "\n",
    "from textblob import TextBlob\n",
    "b = TextBlob(\"I feel very sick today, don't call me unless necessary\")\n",
    "print(b.sentiment)\n",
    "# the result: Sentiment(polarity=-0.4642857142857143, subjectivity=1.0)\n",
    "# polarity is between -1 and 1. Negative means negative sentiment.\n",
    "# -1 (most negative) to 1(most positive)\n",
    "# subjectivity is from 0 to 1. 0 means very objective, 1 means subjective\n",
    "#score of 0.6 means not so subjective or not so objective.\n",
    "#Analysis of op: subjectivity=1.0 means opinion or feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.13333333333333333)\n"
     ]
    }
   ],
   "source": [
    "# sometimes this is not accurate.\n",
    "from textblob import TextBlob\n",
    "b = TextBlob(\"Chinese Government banned Bitcoin related transactions among financial institutes\")\n",
    "print(b.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39166666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try some positive corpus\n",
    "text = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "text.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4357142857142857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. practice with movie reviews sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#professor code\n",
    "with open('positive.txt','r') as f:\n",
    "    reviews = [x.strip('\\n').lower() for x in f.readlines()]\n",
    "# reviews: return a list of reviews\n",
    "num_attempt = 0\n",
    "num_correct = 0\n",
    "\n",
    "for line in reviews:\n",
    "    num_attempt+=1\n",
    "    blob = TextBlob(line)\n",
    "    if blob.sentiment.polarity>0:\n",
    "        num_correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7111236165822548\n"
     ]
    }
   ],
   "source": [
    "#print accuracy\n",
    "print(num_correct/num_attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('negative.txt','r') as f:\n",
    "    reviews = [x.strip('\\n').lower() for x in f.readlines()]\n",
    "\n",
    "num_attempt = 0\n",
    "num_correct = 0\n",
    "\n",
    "for line in reviews:\n",
    "    num_attempt+=1\n",
    "    blob = TextBlob(line)\n",
    "    if blob.sentiment.polarity<0:\n",
    "        num_correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3901706996811105\n"
     ]
    }
   ],
   "source": [
    "print(num_correct/num_attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count=0\n",
    "pos_correct=0\n",
    "\n",
    "with open('positive.txt','r') as f:\n",
    "    text = f.readlines()\n",
    "    for line in text:\n",
    "        blob=TextBlob(line.strip('\\n'))\n",
    "        if blob.sentiment.polarity>0:\n",
    "            pos_correct+=1\n",
    "        pos_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_count=0\n",
    "neg_correct=0\n",
    "\n",
    "with open('negative.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        blob=TextBlob(line.strip('\\n'))\n",
    "        if blob.sentiment.polarity<=0: # including the 0 here.\n",
    "            neg_correct+=1\n",
    "        neg_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7111236165822548\n",
      "0.5586193959857437\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy \n",
    "print(pos_correct/pos_count)\n",
    "print(neg_correct/neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it turns out that the accuracy is not very high\n",
    "# we can try to change the threshold bar from 0 to somewhere else such as 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's try to only look at the reviews that are more objective\n",
    "#subjective reviews are more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787292817679558\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "pos_count=0\n",
    "pos_correct=0\n",
    "\n",
    "with open('positive.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        blob=TextBlob(line.strip('\\n'))\n",
    "        if blob.sentiment.subjectivity>0.8: # we only attempt to rate the reviews with less than 0.3 subjectivity score\n",
    "            if blob.sentiment.polarity>0:\n",
    "                pos_correct+=1\n",
    "            pos_count+=1\n",
    "\n",
    "print(pos_correct/pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64568345323741\n"
     ]
    }
   ],
   "source": [
    "neg_count=0\n",
    "neg_correct=0\n",
    "\n",
    "with open('negative.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        blob=TextBlob(line.strip('\\n'))\n",
    "        if blob.sentiment.subjectivity>0.8: # we only attempt to rate the reviews with less than 0.3 subjectivity score\n",
    "            if blob.sentiment.polarity<=0:\n",
    "                neg_correct+=1\n",
    "            neg_count+=1\n",
    "\n",
    "\n",
    "print(neg_correct/neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with cutoff being -0.3, the accuracy is 0.5584634392901269\n",
      "with cutoff being -0.25, the accuracy is 0.5695832865326295\n",
      "with cutoff being -0.2, the accuracy is 0.5833988543187689\n",
      "with cutoff being -0.15000000000000002, the accuracy is 0.602381219813546\n",
      "with cutoff being -0.10000000000000003, the accuracy is 0.6164214309783219\n",
      "with cutoff being -0.050000000000000044, the accuracy is 0.6385488037740088\n",
      "with cutoff being -5.551115123125783e-17, the accuracy is 0.653262945074694\n",
      "with cutoff being 0.04999999999999993, the accuracy is 0.6593283162978771\n",
      "with cutoff being 0.09999999999999992, the accuracy is 0.6621363585308323\n",
      "with cutoff being 0.1499999999999999, the accuracy is 0.6604515331910592\n",
      "with cutoff being 0.1999999999999999, the accuracy is 0.6495563293271931\n",
      "with cutoff being 0.24999999999999983, the accuracy is 0.633269684376053\n"
     ]
    }
   ],
   "source": [
    "def accuracy(cutoff):\n",
    "    num_attempt = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    with open('positive.txt','r') as f:\n",
    "        reviews = [x.strip('\\n').lower() for x in f.readlines()]\n",
    "        \n",
    "    for line in reviews:\n",
    "        blob = TextBlob(line)\n",
    "#         if blob.sentiment.subjectivity>0.8:\n",
    "        if blob.sentiment.polarity>0.01 or blob.sentiment.polarity<-0.01: #skip/avoid neutral reviews\n",
    "            num_attempt+=1   \n",
    "            if blob.sentiment.polarity>=cutoff:\n",
    "                num_correct += 1\n",
    "\n",
    "    with open('negative.txt','r') as f:\n",
    "        reviews = [x.strip('\\n').lower() for x in f.readlines()]\n",
    "        \n",
    "    for line in reviews:\n",
    "        blob = TextBlob(line)\n",
    "#         if blob.sentiment.subjectivity>0.8:\n",
    "        if blob.sentiment.polarity>0.01 or blob.sentiment.polarity<-0.01: #skip/avoid neutral reviews\n",
    "            num_attempt+=1   \n",
    "            if blob.sentiment.polarity<cutoff:\n",
    "                num_correct += 1\n",
    "\n",
    "    return num_correct/num_attempt\n",
    "\n",
    "for k in np.arange(-0.3,0.3,0.05):\n",
    "        print(\"with cutoff being {}, the accuracy is {}\".format(k,accuracy(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. sentiment analysis with  VADER (Valence Aware Dictionary and sEntiment Reasoner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.285, 'neu': 0.715, 'pos': 0.0, 'compound': -0.5563}\n",
      "{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'compound': -0.4588}\n"
     ]
    }
   ],
   "source": [
    "# different from TextBlob sentiment analysis, which is based on training preclassified data.\n",
    "# the vader sentiment analysis is lexicon based. i.e it is rule-based \n",
    "# meaning that we use a dictionary that maps words to a score from -4 to 4 (-4 is most negative)\n",
    "# in vader lexcon, even emotions are mapped: e.g. /-: and 0:-3 get mapped to  -1.3 and 1.5.\n",
    "# humans are used to rate the score of each word and the scores are averaged.\n",
    "# the sentence sentiment is then normalized sum of the sentiments from each words to keep it from -1 to 1.\n",
    "# x is the sum of sentiment scores from all scored words, and the vader sentence sentiment is x/sqrt(x^2+a), a is usually set to 15.\n",
    "# no need to train positive or negative corpus\n",
    "# more computational efficient than other machine learning and deep learning approaches\n",
    "\n",
    "# if we redo the previous sentiment analysis, we got more convincing results\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "sent=analyzer.polarity_scores(\"I feel very sick today, don't call me unless necessary\")\n",
    "print(sent)\n",
    "sent2=analyzer.polarity_scores(\"Chinese Government banned Bitcoin related transactions among financial institutes\")\n",
    "print(sent2)\n",
    "# we get three sentiments and a compound score. \n",
    "# compound is between -1 and 1.\n",
    "#the cutoff score postive/negative is context dependent. Always better to use sentiment analysis comparatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285\n"
     ]
    }
   ],
   "source": [
    "print(sent['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7019320952916901\n",
      "0.5738135434252486\n"
     ]
    }
   ],
   "source": [
    "# let's try rating the movie ratings\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "pos_count=0\n",
    "pos_correct=0\n",
    "\n",
    "with open('positive.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        scores=analyzer.polarity_scores(line)\n",
    "        if scores['compound']>0:\n",
    "            pos_correct+=1\n",
    "        pos_count+=1\n",
    "\n",
    "neg_count=0\n",
    "neg_correct=0\n",
    "\n",
    "with open('negative.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        scores=analyzer.polarity_scores(line)\n",
    "        if scores['compound']<=0:\n",
    "            neg_correct+=1\n",
    "        neg_count+=1\n",
    "\n",
    "print(pos_correct/pos_count)\n",
    "print(neg_correct/neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textblob: trained\n",
    "#vader: rulesbased. These two are most commonly used in industries\n",
    "#lexicon based sentiment analysis\n",
    "#lexicon1: harvard general inquiry lexicon - general purpose used for academic purpose\n",
    "#lexicon2; Loughran lexicon - used in financial context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Using word count to gauge sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Negative.txt\",'r') as f:\n",
    "    negative=[x.lower().strip('\\n') for x in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010824853864472829\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "f=open('post.txt','r')\n",
    "contents=\" \".join([x.lower() for x in f.readlines()])\n",
    "wordlist=nltk.word_tokenize(contents)\n",
    "length=len(wordlist)\n",
    "negcount=sum([1 if i in negative else 0 for i in wordlist])\n",
    "print(negcount/length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Consider  negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_positive_words = num_raw_pos_word(good) + negated neg word(not bad) - negated neg word(not good)\n",
    "# num_negative_words = num_raw_neg_word(bad) + negated pos word(not good) - negated neg word(not bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "negation=['no', 'not', 'none', 'neither', 'never', 'nobody','nothing','nowhere','hardly','scarcely','barely',\"doesnt\",\"isnt\",\"dont\",\"wasnt\",\"shouldnt\",\"wouldnt\",\"couldnt\",\"wont\",\"cant\"]\n",
    "with open(\"loughran_negative.txt\",'r') as f:\n",
    "    negative=[x.lower().strip('\\n') for x in f.readlines()]\n",
    "with open(\"loughran_positive.txt\",'r') as f:\n",
    "    positive=[x.lower().strip('\\n') for x in f.readlines()]\n",
    "    \n",
    "def negate_pos(text):\n",
    "    count=0\n",
    "    wordlist=nltk.word_tokenize(text)\n",
    "    for index,word in enumerate(wordlist):\n",
    "        if word in positive:\n",
    "            word1=wordlist[index-1] if index>=1 else 'NA'\n",
    "            word2=wordlist[index-2] if index>=2 else \"NA\"\n",
    "            word3=wordlist[index-3] if index>=3 else \"NA\"\n",
    "            if (word1 in negation) or (word2 in negation) or (word3 in negation):\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "def negate_neg(text):\n",
    "    count=0\n",
    "    wordlist=nltk.word_tokenize(text)\n",
    "    for index,word in enumerate(wordlist):\n",
    "        if word in negative:\n",
    "            word1=wordlist[index-1] if index>=1 else 'NA'\n",
    "            word2=wordlist[index-2] if index>=2 else \"NA\"\n",
    "            word3=wordlist[index-3] if index>=3 else \"NA\"\n",
    "            if (word1 in negation) or (word2 in negation) or (word3 in negation):\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "# tries to calculate the sentiment for the following sentence\n",
    "x='the project design is not bad, but the methodology is problematic. While the writing is superb, however the result is not good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Python\n",
      "1\n",
      "is\n",
      "2\n",
      "a\n",
      "3\n",
      "high-level\n",
      "4\n",
      ",\n",
      "5\n",
      "general-purpose\n",
      "6\n",
      "programming\n",
      "7\n",
      "language\n",
      "8\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "wordlist=nltk.word_tokenize(text)\n",
    "for index,word in enumerate(wordlist):\n",
    "    print(index)\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033304467056361406\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "    \n",
    "f=open('post.txt','r')\n",
    "contents=\" \".join([x.lower() for x in f.readlines()]) #words are on the new line\n",
    "wordlist=nltk.word_tokenize(contents)\n",
    "length=len(wordlist)\n",
    "negcount=sum([1 if i in negative else 0 for i in wordlist])\n",
    "print(negcount/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
